{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the data all of the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in length of each data point\n",
    "## Not useful as some coordinate data do not match video lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidLength = {}\n",
    "f = open(\"videoLength.txt\", \"r\")\n",
    "line = f.readline()\n",
    "while (line):\n",
    "    try:\n",
    "        if line.split(\"_|_\")[1] == 'None\\n':\n",
    "            vidLength[line.split(\"_|_\")[0]] = None\n",
    "        else:\n",
    "            vidLength[line.split(\"_|_\")[0]] = int(line.split(\"_|_\")[1])\n",
    "    except:\n",
    "        if line != '\\n':\n",
    "            print(line)\n",
    "    line = f.readline()\n",
    "f.close()\n",
    "vidLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest video length:  ('ZOOM-OFF_STBA1c2b_36540_37860.mp4', 33)\n",
      "Shortest video length:  ('ABOUT1_BFSA1c2a_1630_1990.mp4', 9)\n"
     ]
    }
   ],
   "source": [
    "videos =  list(vidLength.items())\n",
    "\n",
    "maxLength = max(videos)\n",
    "minLength = max(videos)\n",
    "\n",
    "print(\"Longest video length: \", max(videos))\n",
    "print(\"Shortest video length: \", min(videos))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Coordinate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelLocation = 'D:/Thesis/ELAR-Data/label.csv'\n",
    "labelDf = pd.read_csv(labelLocation)\n",
    "labelDict = dict(np.array(labelDf))\n",
    "print(labelDict)\n",
    "\n",
    "X = {}\n",
    "coorDataLocation = \"D:/Thesis/ELAR-Data/arrayData/\"\n",
    "dirData = os.listdir(coorDataLocation)\n",
    "failed = 0\n",
    "print(dirData)\n",
    "for i, data in enumerate(dirData):\n",
    "    if 'shape' in data:\n",
    "        continue\n",
    "    fileLocation = coorDataLocation + data\n",
    "    shapeLocation = coorDataLocation + dirData[i+1]\n",
    "    coorLoad = np.loadtxt(fileLocation)\n",
    "    coorShape= np.loadtxt(shapeLocation)\n",
    "    try:\n",
    "        coorLoad = coorLoad.reshape(coorLoad.shape[0], coorLoad.shape[1] // int(coorShape[2]), int(coorShape[2]))\n",
    "        X[data[:-4]] = coorLoad\n",
    "    except IndexError:\n",
    "        print(failed, fileLocation, shapeLocation)\n",
    "        failed += 1\n",
    "\n",
    "coorData = X\n",
    "# coorData = {Y[i]:x for i, x in enumerate(X)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in length of each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14096"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vidLength = {key: data.shape[0] for key, data in coorData.items()}\n",
    "len(vidLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest video length:  ('ZOOM-OFF_STBA1c2b_36540_37860', 33)\n",
      "Shortest video length:  ('ABOUT1_SBS1A3c7a_950_1280', 9)\n"
     ]
    }
   ],
   "source": [
    "videos =  list(vidLength.items())\n",
    "\n",
    "maxLength = max(videos)\n",
    "minLength = max(videos)\n",
    "\n",
    "print(\"Longest video length: \", max(videos))\n",
    "print(\"Shortest video length: \", min(videos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize Technique\n",
    "### Note the coordinate data is in a 3d array (i,j,k) where the\n",
    "- Where i is the frame\n",
    "- Where j is the 33 different joints\n",
    "- k is the x y z of that specific joing\n",
    "- e.g (22, 33, 3) could be the shape for a data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg = \"ABOUT1_BFSA1c2a_1630_1990\"\n",
    "coordinate = coorData[eg]\n",
    "coordinate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizeLength = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newCoorDic = {}\n",
    "# Impute the mean\n",
    "for name, originalLength in videos:\n",
    "    coordinate = coorData[name]\n",
    "    imputeEvery = originalLength/resizeLength\n",
    "    i = 0\n",
    "    # List of all new Joint location\n",
    "    newCoors = [None] * resizeLength\n",
    "    for newFrame in range(resizeLength):\n",
    "        # new Joint location for a given frame\n",
    "        frameCoors = [None] * 33\n",
    "\n",
    "        # new frame based between these frames\n",
    "        baseFrame = int(np.floor(imputeEvery * newFrame))\n",
    "        nextFrame = int(baseFrame + 1)\n",
    "        if nextFrame >= originalLength:\n",
    "            nextFrame = baseFrame\n",
    "        \n",
    "        # Bias when averaging frames\n",
    "        bias =  1 - ((imputeEvery * newFrame) - baseFrame)\n",
    "        for i in range(33):\n",
    "            xyz = [None] * 3\n",
    "            for j in range(3):\n",
    "                newjoint = ((1 + bias) * coordinate[baseFrame][i][j] \n",
    "                            + (1 - bias) * coordinate[nextFrame][i][j])/2\n",
    "                xyz[j] = newjoint\n",
    "            frameCoors[i] = xyz\n",
    "        newCoors[newFrame] = frameCoors\n",
    "    newCoorDic[name] = newCoors\n",
    "newCoorDic\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PsuedoCode\n",
    "newCoordinates = []\n",
    "for i from 1 to resizeLength\n",
    "    baseFrame = floor(ImputationRatio * i) # \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imputationRatio = originalLength/resizeLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14096, 40, 33, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_data =  np.array(list(newCoorDic.values()))\n",
    "reshaped_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save new Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coor = []\n",
    "for name, coor in newCoorDic.items():\n",
    "    if len(coor) > 0:\n",
    "        coor = np.array(coor)\n",
    "        print(\"saving: \", name)\n",
    "        np.savetxt(\"D:/Thesis/ELAR-Data/heavyImputedArrayData/\"+ name +\".npy\", coor.reshape(coor.shape[0], -1))\n",
    "        np.savetxt(\"D:/Thesis/ELAR-Data/heavyImputedArrayData/\"+ name +\"_shape.npy\", np.array(coor.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
