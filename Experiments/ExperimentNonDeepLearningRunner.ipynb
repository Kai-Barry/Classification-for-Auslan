{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentData = ['experiment1', 'experiment2', 'experiment3', 'experiment5', 'experiment5']\n",
    "folder = experimentData[experiment - 1]\n",
    "# Save Data\n",
    "X_train = np.loadtxt(folder + \"/X_train.npy\")\n",
    "X_test = np.loadtxt(folder + \"/X_test.npy\")\n",
    "y_train = np.loadtxt(folder + \"/y_train.npy\")\n",
    "y_test = np.loadtxt(folder + \"/y_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis\n",
    "Quadratic discriminant analysis is a classification problem represented by a Bayes Probability distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " svd\n",
      "training acuracy:  0.9857928505957837\n",
      "validation acuracy:  0.15892193308550187\n",
      "training error:  0.014207149404216302\n",
      "validation error:  0.8410780669144982\n",
      "\n",
      " lsqr\n",
      "training acuracy:  0.033455545371219066\n",
      "validation acuracy:  0.026022304832713755\n",
      "training error:  0.9665444546287809\n",
      "validation error:  0.9739776951672863\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# data to manipulate\n",
    "ldas = []\n",
    "for solver in ['svd', 'lsqr']:\n",
    "    lda = LinearDiscriminantAnalysis(solver=solver)\n",
    "    lda.fit(X_train, y_train)\n",
    "    ldas.append(lda)\n",
    "    print('\\n', solver)\n",
    "    # Error calculation\n",
    "    print(\"training acuracy: \", lda.score(X_train, y_train))\n",
    "    print(\"validation acuracy: \", lda.score(X_test, y_test))\n",
    "    print(\"training error: \", 1 - lda.score(X_train, y_train))\n",
    "    print(\"validation error: \", 1 - lda.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Discriminant Analysis\n",
    "Quadratic discriminant analysis is a classification problem represented by a Bayes Probability distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KAI\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acuracy:  1.0\n",
      "validation acuracy:  0.13940520446096655\n",
      "training error:  0.0\n",
      "validation error:  0.8605947955390334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "# Error calculation\n",
    "print(\"training acuracy: \", qda.score(X_train, y_train))\n",
    "print(\"validation acuracy: \", qda.score(X_test, y_test))\n",
    "print(\"training error: \", 1 - qda.score(X_train, y_train))\n",
    "print(\"validation error: \", 1 - qda.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes\n",
    "models each as conforming to a Gaussian (normal) distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acuracy:  0.18056828597616864\n",
      "validation acuracy:  0.1449814126394052\n",
      "training error:  0.8194317140238314\n",
      "validation error:  0.8550185873605948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "print(\"training acuracy: \", gnb.score(X_train, y_train))\n",
    "print(\"validation acuracy: \", gnb.score(X_test, y_test))\n",
    "print(\"training error: \", 1 - gnb.score(X_train, y_train))\n",
    "print(\"validation error: \", 1 - gnb.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighbors Classifier\n",
    "Classifier implementing the k-nearest neighbors vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=1)\n",
      "training acuracy:  1.0\n",
      "validation acuracy:  0.21189591078066913\n",
      "training error:  0.0\n",
      "validation error:  0.7881040892193308\n",
      "\n",
      "\n",
      "KNeighborsClassifier()\n",
      "training acuracy:  0.45875343721356554\n",
      "validation acuracy:  0.19423791821561337\n",
      "training error:  0.5412465627864345\n",
      "validation error:  0.8057620817843867\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=10)\n",
      "training acuracy:  0.3611365719523373\n",
      "validation acuracy:  0.19981412639405205\n",
      "training error:  0.6388634280476627\n",
      "validation error:  0.800185873605948\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=15)\n",
      "training acuracy:  0.32538955087076077\n",
      "validation acuracy:  0.2100371747211896\n",
      "training error:  0.6746104491292393\n",
      "validation error:  0.7899628252788105\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=20)\n",
      "training acuracy:  0.29605866177818513\n",
      "validation acuracy:  0.2137546468401487\n",
      "training error:  0.7039413382218149\n",
      "validation error:  0.7862453531598513\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=25)\n",
      "training acuracy:  0.2827681026581118\n",
      "validation acuracy:  0.2137546468401487\n",
      "training error:  0.7172318973418882\n",
      "validation error:  0.7862453531598513\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=30)\n",
      "training acuracy:  0.27268560953253895\n",
      "validation acuracy:  0.2100371747211896\n",
      "training error:  0.727314390467461\n",
      "validation error:  0.7899628252788105\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=1)\n",
      "training acuracy:  1.0\n",
      "validation acuracy:  0.21189591078066913\n",
      "training error:  0.0\n",
      "validation error:  0.7881040892193308\n",
      "\n",
      "\n",
      "KNeighborsClassifier()\n",
      "training acuracy:  0.45875343721356554\n",
      "validation acuracy:  0.19423791821561337\n",
      "training error:  0.5412465627864345\n",
      "validation error:  0.8057620817843867\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=10)\n",
      "training acuracy:  0.3611365719523373\n",
      "validation acuracy:  0.19981412639405205\n",
      "training error:  0.6388634280476627\n",
      "validation error:  0.800185873605948\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=15)\n",
      "training acuracy:  0.32538955087076077\n",
      "validation acuracy:  0.2100371747211896\n",
      "training error:  0.6746104491292393\n",
      "validation error:  0.7899628252788105\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=20)\n",
      "training acuracy:  0.29605866177818513\n",
      "validation acuracy:  0.2137546468401487\n",
      "training error:  0.7039413382218149\n",
      "validation error:  0.7862453531598513\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=25)\n",
      "training acuracy:  0.2827681026581118\n",
      "validation acuracy:  0.2137546468401487\n",
      "training error:  0.7172318973418882\n",
      "validation error:  0.7862453531598513\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=30)\n",
      "training acuracy:  0.27268560953253895\n",
      "validation acuracy:  0.2100371747211896\n",
      "training error:  0.727314390467461\n",
      "validation error:  0.7899628252788105\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=1, weights='distance')\n",
      "training acuracy:  1.0\n",
      "validation acuracy:  0.21189591078066913\n",
      "training error:  0.0\n",
      "validation error:  0.7881040892193308\n",
      "\n",
      "\n",
      "KNeighborsClassifier(weights='distance')\n",
      "training acuracy:  1.0\n",
      "validation acuracy:  0.20910780669144982\n",
      "training error:  0.0\n",
      "validation error:  0.7908921933085502\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
      "training acuracy:  1.0\n",
      "validation acuracy:  0.21468401486988847\n",
      "training error:  0.0\n",
      "validation error:  0.7853159851301115\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
      "training acuracy:  1.0\n",
      "validation acuracy:  0.2100371747211896\n",
      "training error:  0.0\n",
      "validation error:  0.7899628252788105\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=20, weights='distance')\n",
      "training acuracy:  1.0\n",
      "validation acuracy:  0.2184014869888476\n",
      "training error:  0.0\n",
      "validation error:  0.7815985130111525\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=25, weights='distance')\n",
      "training acuracy:  1.0\n",
      "validation acuracy:  0.2128252788104089\n",
      "training error:  0.0\n",
      "validation error:  0.7871747211895911\n",
      "\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=30, weights='distance')\n",
      "training acuracy:  1.0\n",
      "validation acuracy:  0.21933085501858737\n",
      "training error:  0.0\n",
      "validation error:  0.7806691449814126\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bottom = 0\n",
    "top = 31\n",
    "step = 5\n",
    "predictClass = []\n",
    "kNeighborsPredictions = []\n",
    "for weight in ['uniform', 'distance']:\n",
    "    for i in range(bottom, top,step):\n",
    "        if i == 0:\n",
    "            clf = KNeighborsClassifier(n_neighbors=1, weights=weight)\n",
    "        else:\n",
    "            clf = KNeighborsClassifier(n_neighbors=i, weights=weight)\n",
    "        clf.fit(X_train, y_train)\n",
    "        kNeighborsPredictions.append(clf)\n",
    "    for neigh in kNeighborsPredictions:\n",
    "        print(neigh)\n",
    "        # Error calculation\n",
    "        print(\"training acuracy: \", neigh.score(X_train, y_train))\n",
    "        print(\"validation acuracy: \", neigh.score(X_test, y_test))\n",
    "        print(\"training error: \", 1 - neigh.score(X_train, y_train))\n",
    "        print(\"validation error: \", 1- neigh.score(X_test, y_test))\n",
    "        print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "A decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criteria:  gini splitter:  best\n",
      "training acuracy:  0.5494958753437214\n",
      "validation acuracy:  0.20446096654275092\n",
      "criteria:  gini splitter:  random\n",
      "training acuracy:  0.5013748854262144\n",
      "validation acuracy:  0.21561338289962825\n",
      "criteria:  entropy splitter:  best\n",
      "training acuracy:  0.6668194317140238\n",
      "validation acuracy:  0.1979553903345725\n",
      "criteria:  entropy splitter:  random\n",
      "training acuracy:  0.5701191567369386\n",
      "validation acuracy:  0.2100371747211896\n",
      "criteria:  log_loss splitter:  best\n",
      "training acuracy:  0.6672777268560953\n",
      "validation acuracy:  0.19237918215613384\n",
      "criteria:  log_loss splitter:  random\n",
      "training acuracy:  0.571494042163153\n",
      "validation acuracy:  0.20446096654275092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for criteria in [\"gini\", \"entropy\", \"log_loss\"]:\n",
    "    for splitter in [\"best\", \"random\"]:\n",
    "        if experiment == 5:\n",
    "            deTree = DecisionTreeClassifier(criterion=criteria, splitter=splitter, max_depth=10, min_samples_split=10, class_weight='balanced')\n",
    "        else:\n",
    "            deTree = DecisionTreeClassifier(criterion=criteria, splitter=splitter, max_depth=10, min_samples_split=10)\n",
    "        print('criteria: ', criteria, 'splitter: ', splitter)\n",
    "        deTree.fit(X_train, y_train)\n",
    "\n",
    "        print(\"training acuracy: \", deTree.score(X_train, y_train))\n",
    "        print(\"validation acuracy: \", deTree.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier\n",
    "A random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=8, min_samples_split=10) gini\n",
      "training acuracy:  0.6819431714023831\n",
      "validation acuracy:  0.30111524163568776\n",
      "training error:  0.31805682859761686\n",
      "validation error:  0.6988847583643123\n",
      "RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=10) entropy\n",
      "training acuracy:  0.812557286892759\n",
      "validation acuracy:  0.30111524163568776\n",
      "training error:  0.18744271310724103\n",
      "validation error:  0.6988847583643123\n",
      "RandomForestClassifier(criterion='log_loss', max_depth=8, min_samples_split=10) log_loss\n",
      "training acuracy:  0.8244729605866178\n",
      "validation acuracy:  0.30390334572490707\n",
      "training error:  0.1755270394133822\n",
      "validation error:  0.6960966542750929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for criteria in [\"gini\", \"entropy\", \"log_loss\"]:\n",
    "    if experiment == 5:\n",
    "        rfc = RandomForestClassifier(criterion=criteria, min_samples_split=10, max_depth=8, class_weight='balanced')\n",
    "    else:\n",
    "        rfc = RandomForestClassifier(criterion=criteria, min_samples_split=10, max_depth=8)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    print(rfc, criteria)\n",
    "    print(\"training acuracy: \", rfc.score(X_train, y_train))\n",
    "    print(\"validation acuracy: \", rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model\n",
    "Save which ever model you deem the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "with open(folder  + '/LDA.pkl', 'wb') as file:\n",
    "    pickle.dump(lda, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "with open(folder  + '/QDA.pkl', 'wb') as file:\n",
    "    pickle.dump(qda, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "with open(folder  + '/GNB.pkl', 'wb') as file:\n",
    "    pickle.dump(gnb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "with open(folder  + '/KNN.pkl', 'wb') as file:\n",
    "    pickle.dump(knn, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "with open(folder  + '/DTC.pkl', 'wb') as file:\n",
    "    pickle.dump(dtc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "with open(folder  + '/RFC.pkl', 'wb') as file:\n",
    "    pickle.dump(rfc, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
